{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping!\n",
    "\n",
    "I use multithreading to speed up scraping and store results in a queue for thread safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import logging\n",
    "from queue import Queue\n",
    "# Athlete ID range (I checked manually)\n",
    "start_id = 1\n",
    "end_id = 16460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete Information (birthday, country, height, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='athlete_data_errors.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "def fetch_athlete_data(athlete_id, data_queue, failed_queue):\n",
    "    headers = {\n",
    "        'X-Csrf-Token': 'QsiFWuxEY1S9h_-dQgRA_7S5w9uvvmXsjq56QbTPw4i_g_XR68rMCBFFhW6HngBRtHskfN5yjX8GQmawqs8BlQ',\n",
    "        'Referer': 'https://ifsc.results.info',\n",
    "        'Cookie': 'session_id=_verticallife_resultservice_session=6RHN3xZrXnftTiScNfSHg7BVvuebLzGAmC9P5vIpzdySn2vG7VwQpjSZRDHug%2BPKCWlkt831HjLvHsPoVKrzTGsPVR6mqSOtjHB%2Bwht%2Bj39KxYO%2FJlaU6zmh8VhNFEl9bXHiOlPGk8AxnZqiBSYKTxJFCqh34nqdurXfFDcsRnbEtYCixcOdx%2F32E4zYGLVw7DSXXIKOVTUivS43UJZq5zDWPctX95UWm%2FD7%2B6UYT2s0B%2B3XJVPgjMWCMR%2FVZs%2FQC45Gjm4uCpHHe8Yt73nM3J%2Br43V1HuHGSvRpRczrJ4QdovlJHDEpg4rjUA%3D%3D',\n",
    "    }\n",
    "    url = f\"https://ifsc.results.info/api/v1/athletes/{athlete_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=120)\n",
    "        if response.status_code == 200:\n",
    "            athlete_data = response.json()\n",
    "            # Ensure we handle missing fields safely using .get()\n",
    "            data_queue.put({\n",
    "                'athlete_id': athlete_data.get('id', None),\n",
    "                'firstname': athlete_data.get('firstname', None),\n",
    "                'lastname': athlete_data.get('lastname', None),\n",
    "                'age': athlete_data.get('age', None),\n",
    "                'gender': athlete_data.get('gender', None),\n",
    "                'country': athlete_data.get('country', None),\n",
    "                'height': athlete_data.get('height', None),\n",
    "                'arm_span': athlete_data.get('arm_span', None),\n",
    "                'paraclimbing_sport_class': athlete_data.get('paraclimbing_sport_class', None),\n",
    "                'birthday': athlete_data.get('birthday', None),\n",
    "            })\n",
    "        else:\n",
    "            logging.error(f\"Failed to fetch athlete ID {athlete_id}: Status {response.status_code}, Reason: {response.reason}\")\n",
    "            failed_queue.put(athlete_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching data for athlete ID {athlete_id}: {e}\")\n",
    "        failed_queue.put(athlete_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_failed_athlete_info(failed_ids, max_retries=2, delay=2):\n",
    "    retry_results = []\n",
    "    failed_queue = Queue()\n",
    "\n",
    "    for retry_count in range(max_retries):\n",
    "        print(f\"Retry attempt {retry_count + 1} for {len(failed_ids)} failed athlete IDs\")\n",
    "        retry_futures = []\n",
    "        data_queue = Queue()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            retry_futures = {executor.submit(fetch_athlete_data, athlete_id, data_queue, failed_queue): athlete_id for athlete_id in failed_ids}\n",
    "            failed_ids = []  # Reset failed_ids list for next retry\n",
    "        \n",
    "            for future in as_completed(retry_futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error during retry for athlete: {e}\")\n",
    "        \n",
    "        # Collect results from queues\n",
    "        while not data_queue.empty():\n",
    "            retry_results.append(data_queue.get())\n",
    "        \n",
    "        while not failed_queue.empty():\n",
    "            failed_ids.append(failed_queue.get())\n",
    "        \n",
    "        if not failed_ids:\n",
    "            break  # Exit loop if no more failed IDs\n",
    "        \n",
    "        time.sleep(delay)  # Wait between retries to avoid overloading the server\n",
    "    \n",
    "    if failed_ids:\n",
    "        print(f\"Final failed athlete IDs after {max_retries} retries: {failed_ids}\")\n",
    "    \n",
    "    return retry_results, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_athletes_parallel(start_id, end_id, max_workers=25):\n",
    "    athletes_info = []\n",
    "    failed_ids = []\n",
    "    data_queue = Queue()\n",
    "    failed_queue = Queue()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks for each athlete ID\n",
    "        futures = {executor.submit(fetch_athlete_data, athlete_id, data_queue, failed_queue): athlete_id for athlete_id in range(start_id, end_id + 1)}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during scraping: {e}\")\n",
    "    \n",
    "    # Collect results from queues\n",
    "    while not data_queue.empty():\n",
    "        athletes_info.append(data_queue.get())\n",
    "    \n",
    "    while not failed_queue.empty():\n",
    "        failed_ids.append(failed_queue.get())\n",
    "    \n",
    "    # Retry for failed athlete IDs\n",
    "    if failed_ids:\n",
    "        retry_results, failed_ids = retry_failed_athlete_info(failed_ids)\n",
    "        athletes_info.extend(retry_results)  # Add successful retries\n",
    "\n",
    "    return athletes_info, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry attempt 1 for 236 failed athlete IDs\n",
      "Retry attempt 2 for 202 failed athlete IDs\n",
      "Final failed athlete IDs after 2 retries: [1861, 1460, 2130, 332, 3423, 548, 581, 3307, 449, 3325, 608, 1414, 34, 545, 2300, 1096, 1253, 453, 2127, 590, 3666, 3720, 3495, 4250, 3902, 4255, 4259, 4264, 4256, 4262, 4268, 3924, 4254, 4257, 4263, 4253, 4265, 4270, 4267, 4271, 4276, 4273, 4278, 4269, 4261, 4279, 4277, 4280, 4266, 4294, 4295, 4281, 4298, 4258, 4302, 4297, 4287, 4291, 4292, 4312, 4309, 4311, 4315, 4313, 4314, 4321, 4317, 4326, 4296, 4348, 4351, 4350, 4331, 4288, 4325, 4316, 4354, 4332, 4353, 4356, 4352, 4349, 4335, 4355, 4357, 4346, 4362, 4897, 5680, 4318, 4671, 5867, 5864, 5866, 6186, 5967, 5519, 5899, 5553, 7249, 7844, 7491, 8727, 9340, 8366, 8038, 10336, 4361, 10828, 9807, 11003, 10042, 10045, 9780, 10146, 10174, 10332, 9712, 10592, 10341, 10794, 11183, 10548, 11002, 11236, 7370, 11392, 11922, 11649, 11923, 11927, 11532, 11539, 11930, 11925, 11926, 11929, 11407, 11924, 11928, 11933, 11934, 11936, 11943, 11937, 11931, 12091, 11987, 11935, 11932, 11997, 12167, 12205, 12115, 12106, 12373, 12403, 12740, 13121, 12711, 13394, 13166, 13448, 14082, 13501, 13513, 13514, 14081, 14083, 14080, 14084, 14079, 14078, 14467, 14429, 14167, 14160, 14466, 14812, 14630, 15275, 15339, 15266, 15900, 15581, 15901, 15905, 16004, 15902, 15993, 15904, 16027, 15906, 15903, 16003, 15992, 16030, 16305, 16028, 16317, 16026, 14927]\n",
      "Scraped 16258 athletes\n",
      "Failed to fetch data for 202 athlete IDs after retries: [1861, 1460, 2130, 332, 3423, 548, 581, 3307, 449, 3325, 608, 1414, 34, 545, 2300, 1096, 1253, 453, 2127, 590, 3666, 3720, 3495, 4250, 3902, 4255, 4259, 4264, 4256, 4262, 4268, 3924, 4254, 4257, 4263, 4253, 4265, 4270, 4267, 4271, 4276, 4273, 4278, 4269, 4261, 4279, 4277, 4280, 4266, 4294, 4295, 4281, 4298, 4258, 4302, 4297, 4287, 4291, 4292, 4312, 4309, 4311, 4315, 4313, 4314, 4321, 4317, 4326, 4296, 4348, 4351, 4350, 4331, 4288, 4325, 4316, 4354, 4332, 4353, 4356, 4352, 4349, 4335, 4355, 4357, 4346, 4362, 4897, 5680, 4318, 4671, 5867, 5864, 5866, 6186, 5967, 5519, 5899, 5553, 7249, 7844, 7491, 8727, 9340, 8366, 8038, 10336, 4361, 10828, 9807, 11003, 10042, 10045, 9780, 10146, 10174, 10332, 9712, 10592, 10341, 10794, 11183, 10548, 11002, 11236, 7370, 11392, 11922, 11649, 11923, 11927, 11532, 11539, 11930, 11925, 11926, 11929, 11407, 11924, 11928, 11933, 11934, 11936, 11943, 11937, 11931, 12091, 11987, 11935, 11932, 11997, 12167, 12205, 12115, 12106, 12373, 12403, 12740, 13121, 12711, 13394, 13166, 13448, 14082, 13501, 13513, 13514, 14081, 14083, 14080, 14084, 14079, 14078, 14467, 14429, 14167, 14160, 14466, 14812, 14630, 15275, 15339, 15266, 15900, 15581, 15901, 15905, 16004, 15902, 15993, 15904, 16027, 15906, 15903, 16003, 15992, 16030, 16305, 16028, 16317, 16026, 14927]\n"
     ]
    }
   ],
   "source": [
    "# Scrape athlete data from the range and create a DataFrame\n",
    "athletes_info_list, failed_ids = scrape_athletes_parallel(start_id, end_id)\n",
    "athletes_info_df = pd.DataFrame(athletes_info_list)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "athletes_info_df.to_csv('athlete_information.csv', index=False)\n",
    "\n",
    "print(f\"Scraped {len(athletes_info_df)} athletes\")\n",
    "if failed_ids:\n",
    "    print(f\"Failed to fetch data for {len(failed_ids)} athlete IDs after retries: {failed_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='scraping_errors.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "def fetch_athlete_results(athlete_id, results_queue, failed_queue):\n",
    "    headers = {\n",
    "        'X-Csrf-Token': 'QsiFWuxEY1S9h_-dQgRA_7S5w9uvvmXsjq56QbTPw4i_g_XR68rMCBFFhW6HngBRtHskfN5yjX8GQmawqs8BlQ',\n",
    "        'Referer': 'https://ifsc.results.info',\n",
    "        'Cookie': 'session_id=_verticallife_resultservice_session=6RHN3xZrXnftTiScNfSHg7BVvuebLzGAmC9P5vIpzdySn2vG7VwQpjSZRDHug%2BPKCWlkt831HjLvHsPoVKrzTGsPVR6mqSOtjHB%2Bwht%2Bj39KxYO%2FJlaU6zmh8VhNFEl9bXHiOlPGk8AxnZqiBSYKTxJFCqh34nqdurXfFDcsRnbEtYCixcOdx%2F32E4zYGLVw7DSXXIKOVTUivS43UJZq5zDWPctX95UWm%2FD7%2B6UYT2s0B%2B3XJVPgjMWCMR%2FVZs%2FQC45Gjm4uCpHHe8Yt73nM3J%2Br43V1HuHGSvRpRczrJ4QdovlJHDEpg4rjUA%3D%3D',\n",
    "    }\n",
    "    url = f\"https://ifsc.results.info/api/v1/athletes/{athlete_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            athlete_data = response.json()\n",
    "            results = []\n",
    "            \n",
    "            for result in athlete_data.get('all_results', []):\n",
    "                # Use `.get()` with default values to avoid KeyErrors if fields are missing\n",
    "                results.append({\n",
    "                    'athlete_id': athlete_id,\n",
    "                    'rank': result.get('rank', None),  # Use None if 'rank' is missing\n",
    "                    'discipline': result.get('discipline', None),\n",
    "                    'season': result.get('season', None),\n",
    "                    'date': result.get('date', None),\n",
    "                    'event_id': result.get('event_id', None),\n",
    "                    'event_location': result.get('event_location', None),\n",
    "                    'd_cat': result.get('d_cat', None),\n",
    "                })\n",
    "            results_queue.put(results)\n",
    "        else:\n",
    "            logging.error(f\"Failed to fetch athlete ID {athlete_id}: Status {response.status_code}, Reason: {response.reason}\")\n",
    "            failed_queue.put(athlete_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching results for athlete ID {athlete_id}: {e}\")\n",
    "        failed_queue.put(athlete_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_failed_athletes(failed_ids, max_retries=3, delay=2):\n",
    "    retry_results = []\n",
    "    failed_queue = Queue()\n",
    "\n",
    "    for retry_count in range(max_retries):\n",
    "        print(f\"Retry attempt {retry_count + 1} for {len(failed_ids)} failed athlete IDs\")\n",
    "        retry_futures = []\n",
    "        results_queue = Queue()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            retry_futures = {executor.submit(fetch_athlete_results, athlete_id, results_queue, failed_queue): athlete_id for athlete_id in failed_ids}\n",
    "            failed_ids = []  # Reset failed_ids list for next retry\n",
    "        \n",
    "            for future in as_completed(retry_futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error during retry for athlete: {e}\")\n",
    "        \n",
    "        # Collect results from queues\n",
    "        while not results_queue.empty():\n",
    "            retry_results.extend(results_queue.get())\n",
    "        \n",
    "        while not failed_queue.empty():\n",
    "            failed_ids.append(failed_queue.get())\n",
    "        \n",
    "        if not failed_ids:\n",
    "            break  # Exit loop if no more failed IDs\n",
    "        \n",
    "        time.sleep(delay)  # Wait between retries to avoid overloading the server\n",
    "    \n",
    "    if failed_ids:\n",
    "        print(f\"Final failed athlete IDs after {max_retries} retries: {failed_ids}\")\n",
    "    \n",
    "    return retry_results, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_athlete_results_parallel(start_id, end_id, max_workers=60):\n",
    "    athlete_results = []\n",
    "    failed_ids = []\n",
    "    results_queue = Queue()\n",
    "    failed_queue = Queue()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(fetch_athlete_results, athlete_id, results_queue, failed_queue): athlete_id for athlete_id in range(start_id, end_id + 1)}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during scraping: {e}\")\n",
    "    \n",
    "    # Collect results from queues\n",
    "    while not results_queue.empty():\n",
    "        athlete_results.extend(results_queue.get())\n",
    "    \n",
    "    while not failed_queue.empty():\n",
    "        failed_ids.append(failed_queue.get())\n",
    "    \n",
    "    # Retry for failed athlete IDs\n",
    "    if failed_ids:\n",
    "        retry_results, failed_ids = retry_failed_athletes(failed_ids)\n",
    "        athlete_results.extend(retry_results)  # Add successful retries\n",
    "    \n",
    "    return athlete_results, failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry attempt 1 for 221 failed athlete IDs\n",
      "Retry attempt 2 for 202 failed athlete IDs\n",
      "Retry attempt 3 for 202 failed athlete IDs\n",
      "Final failed athlete IDs after 3 retries: [545, 3325, 34, 332, 2300, 548, 1414, 2127, 449, 590, 3423, 1460, 2130, 581, 1253, 1096, 3307, 453, 608, 1861, 3666, 3495, 3902, 3924, 3720, 4268, 4254, 4256, 4258, 4259, 4257, 4253, 4262, 4250, 4264, 4255, 4266, 4267, 4261, 4263, 4265, 4270, 4269, 4287, 4278, 4273, 4277, 4279, 4280, 4276, 4292, 4291, 4296, 4298, 4297, 4271, 4294, 4281, 4288, 4295, 4309, 4313, 4302, 4315, 4318, 4317, 4311, 4312, 4321, 4332, 4326, 4346, 4335, 4316, 4351, 4314, 4331, 4325, 4350, 4348, 4352, 4349, 4356, 4354, 4353, 4355, 4671, 4361, 4897, 5519, 4362, 5867, 5967, 5553, 5899, 5680, 4357, 5866, 6186, 5864, 7491, 8366, 7249, 7370, 7844, 9340, 8727, 8038, 9780, 9807, 10042, 10174, 10045, 10146, 10336, 9712, 10341, 10548, 10592, 10332, 10794, 10828, 11183, 11002, 11236, 11392, 11003, 11539, 11407, 11649, 11925, 11928, 11924, 11532, 11922, 11931, 11927, 11926, 11932, 11936, 11933, 11943, 11934, 11937, 11929, 11987, 11935, 11997, 11923, 11930, 12106, 12115, 12205, 12403, 13448, 12167, 13394, 12091, 12740, 12373, 12711, 13513, 13166, 13514, 13121, 13501, 14078, 14082, 14080, 14083, 14167, 14429, 14081, 14160, 14079, 14466, 14630, 14467, 15275, 14084, 15339, 15266, 14812, 15581, 15902, 15903, 15904, 14927, 15905, 15992, 15901, 15906, 15900, 16003, 16028, 16317, 16004, 16026, 16027, 15993, 16030, 16305]\n",
      "Scraped results for 135444 athlete events\n",
      "Failed to fetch data for 202 athlete IDs after retries: [545, 3325, 34, 332, 2300, 548, 1414, 2127, 449, 590, 3423, 1460, 2130, 581, 1253, 1096, 3307, 453, 608, 1861, 3666, 3495, 3902, 3924, 3720, 4268, 4254, 4256, 4258, 4259, 4257, 4253, 4262, 4250, 4264, 4255, 4266, 4267, 4261, 4263, 4265, 4270, 4269, 4287, 4278, 4273, 4277, 4279, 4280, 4276, 4292, 4291, 4296, 4298, 4297, 4271, 4294, 4281, 4288, 4295, 4309, 4313, 4302, 4315, 4318, 4317, 4311, 4312, 4321, 4332, 4326, 4346, 4335, 4316, 4351, 4314, 4331, 4325, 4350, 4348, 4352, 4349, 4356, 4354, 4353, 4355, 4671, 4361, 4897, 5519, 4362, 5867, 5967, 5553, 5899, 5680, 4357, 5866, 6186, 5864, 7491, 8366, 7249, 7370, 7844, 9340, 8727, 8038, 9780, 9807, 10042, 10174, 10045, 10146, 10336, 9712, 10341, 10548, 10592, 10332, 10794, 10828, 11183, 11002, 11236, 11392, 11003, 11539, 11407, 11649, 11925, 11928, 11924, 11532, 11922, 11931, 11927, 11926, 11932, 11936, 11933, 11943, 11934, 11937, 11929, 11987, 11935, 11997, 11923, 11930, 12106, 12115, 12205, 12403, 13448, 12167, 13394, 12091, 12740, 12373, 12711, 13513, 13166, 13514, 13121, 13501, 14078, 14082, 14080, 14083, 14167, 14429, 14081, 14160, 14079, 14466, 14630, 14467, 15275, 14084, 15339, 15266, 14812, 15581, 15902, 15903, 15904, 14927, 15905, 15992, 15901, 15906, 15900, 16003, 16028, 16317, 16004, 16026, 16027, 15993, 16030, 16305]\n"
     ]
    }
   ],
   "source": [
    "athlete_results_list, failed_ids = scrape_athlete_results_parallel(start_id, end_id)\n",
    "athlete_results_df = pd.DataFrame(athlete_results_list)\n",
    "\n",
    "athlete_results_df.to_csv('athlete_results.csv', index=False)\n",
    "\n",
    "print(f\"Scraped results for {len(athlete_results_df)} athlete events\")\n",
    "if failed_ids:\n",
    "    print(f\"Failed to fetch data for {len(failed_ids)} athlete IDs after retries: {failed_ids}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
